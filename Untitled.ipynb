{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6291b58c-33d7-4618-87d7-6acca2f5a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0652fa8f-5828-4feb-9c8f-8e06bd3e1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b792961f-2678-4d4b-953a-d1d3a08fa65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_num = 1.0 - np.power(0.999, [10,20,100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79332b01-3861-4cad-a5f3-176fb8a4f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89cae71d-fc71-4a22-857d-1d0b04422067",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= nn.ModuleList([nn.Linear(20, 1) for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "145a0633-afc1-4e78-86e9-78b94f026da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=20, out_features=1, bias=True)\n",
       "  (1): Linear(in_features=20, out_features=1, bias=True)\n",
       "  (2): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bbc3353-4677-4eaa-bba8-685914beb5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=20, out_features=1, bias=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c478993d-2a86-4cb0-af62-5cc32d2992be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21184078-d6ba-466a-9d34-8c9046e26df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (1.0 - 0.999) / np.array(effective_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59dd5768-0674-4768-b7ad-18f9e0e529d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights / np.sum(weights) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cde99f6-e9f0-4e69-bc54-4628bb0f8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.tensor(1)\n",
    "t2 = torch.tensor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "062ccd86-2cdf-45c4-acbc-51fc22a105a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {1:None, 2:torch.tensor([1,2,3])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40be66c6-6ab1-4c1a-8695-2f5d6dfceab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: None, 2: [1, 2, 3]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i:j.tolist() if j is not None else j for i,j in weights.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da1b60a8-3d08-4b89-b49f-e4b867168824",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_42560/1218765265.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType"
     ]
    }
   ],
   "source": [
    "torch.tensor(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68985c66-6623-4f55-9a52-c35a2ad52e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1+t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22a8a5df-28fc-4614-bd1a-79d2d0b5aef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor input, *, torch.dtype dtype)\n * (Tensor input, tuple of ints dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of names dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_42560/882798467.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sum() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor input, *, torch.dtype dtype)\n * (Tensor input, tuple of ints dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n * (Tensor input, tuple of names dim, bool keepdim, *, torch.dtype dtype, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "torch.sum(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e2674d2-3903-41e3-8cb0-071000ddd217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f443d554-1844-4849-a2f3-519cd4df985d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8667592, 0.9380488, 0.195192 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfde096d-9981-44b7-b50a-38abc31c18e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 0.05, 0.01)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/10, 1/20, 1/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ab42a-8e20-412f-951c-2aa26b54d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = (1.0 - self.beta) / np.array(effective_num)\n",
    "weights = weights / np.sum(weights) * num_classes\n",
    "weights = torch.tensor(weights, device=logits.device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df764b67-34b4-44c9-8bb0-b7a28b84e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler, RandomSampler, SequentialSampler\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, BertModel, RobertaModel, T5EncoderModel, get_constant_schedule_with_warmup\n",
    "import argparse\n",
    "from utils.data_utils import *\n",
    "from utils.distributed_utils import *\n",
    "from utils.utils import *\n",
    "from model import *\n",
    "from losses import *\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def calc_loss(args, logits, labels, weights=None):\n",
    "    # label에 따른 차이가 필요함.\n",
    "    if args.n_labels != 1:\n",
    "        if args.weighted_cross_entropy:\n",
    "            loss_fn = nn.CrossEntropyLoss(weight=weights.to(labels))\n",
    "            # just for binary classification\n",
    "        elif args.focal_loss:\n",
    "            loss_fn = FocalLoss(args.gamma)\n",
    "        else:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "    else:\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        logits = logits.squeeze(1)\n",
    "        labels = labels.float()\n",
    "    loss = loss_fn(logits, labels)\n",
    "    return loss\n",
    "\n",
    "# evaluation\n",
    "def evaluation(args, model, tokenizer, eval_dataloader):\n",
    "    total_loss = 0.\n",
    "    model.eval()\n",
    "    predicts = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(eval_dataloader, desc = 'evaluate', disable =  args.local_rank not in [-1,0]):\n",
    "            data = {i:j.cuda() for i,j in data.items()}\n",
    "            output = model.forward(**data)\n",
    "            if output.get('loss') is not None:\n",
    "                loss = calc_loss(args, output['score'], data['labels'], weights=weights)\n",
    "                total_loss+=loss\n",
    "            if args.n_labels == 1:\n",
    "                predict = (torch.sigmoid(output['score'])>=0.5).squeeze(1).long().cpu().tolist()\n",
    "            else:\n",
    "                predict = output['score'].argmax(dim=-1).cpu().tolist()\n",
    "            actual = data['labels'].cpu().tolist()\n",
    "            predicts.extend(predict)\n",
    "            actuals.extend(actual)\n",
    "    acc = accuracy_score(actuals, predicts)\n",
    "    f1 = f1_score(actuals, predicts, average='weighted')\n",
    "    cnt = len(predicts)\n",
    "    return dict(loss=total_loss/len(eval_dataloader), acc=acc, f1=f1, cnt=cnt)\n",
    "\n",
    "def get_scores(local_rank, scores, distributed:bool):\n",
    "    if distributed:\n",
    "        cnt = sum([j.item() for j in get_global(local_rank, torch.tensor([scores['cnt']]).cuda())])\n",
    "        acc = sum([j.item() for j in get_global(local_rank, torch.tensor([scores['acc']]).cuda())])\n",
    "        f1 = sum([j.item() for j in get_global(local_rank, torch.tensor([scores['f1']]).cuda())])\n",
    "        total_loss = [j.item() for j in get_global(local_rank, torch.tensor([scores['loss']]).cuda())]\n",
    "        total_loss = sum(total_loss)/len(total_loss) \n",
    "    else:\n",
    "        acc = scores['acc']\n",
    "        f1 = scores['f1']\n",
    "        total_loss = scores['loss']\n",
    "    return dict(loss=np.round(total_loss,3), acc=np.round(acc,3), f1 = np.round(f1, 3))\n",
    "\n",
    "def get_args():\n",
    "    # parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--test_name', type=str, help = 'test_name')\n",
    "    parser.add_argument('--output_dir', type=str, help = 'output 위치')\n",
    "    # data\n",
    "    parser.add_argument('--train_data', type=str, help = 'train_data 위치')\n",
    "    parser.add_argument('--val_data', type=str, help='val data 위치')\n",
    "    parser.add_argument('--n_labels', type=int)\n",
    "    \n",
    "    # logging 관련\n",
    "    parser.add_argument('--logging_term', type=int, default = 100)\n",
    "   \n",
    "    # 학습 관련\n",
    "    parser.add_argument('--epochs', type=int, default = 20)\n",
    "    parser.add_argument('--eval_epoch', type = int, default = 1, help = 'term of evaluation')\n",
    "    parser.add_argument('--batch_size', default = 8, type=int)\n",
    "    parser.add_argument('--lr', type=float, default = 5e-5)\n",
    "    parser.add_argument('--warmup', type=float, default = 0.05)\n",
    "    parser.add_argument('--decay', type=float, default = 0.1)\n",
    "    parser.add_argument('--accumulation_steps', type=int, default = 1) # 221124 추가\n",
    "    \n",
    "    # 경량화\n",
    "    parser.add_argument('--fp16', type=str2bool, default = True)\n",
    "    \n",
    "    # imbalance\n",
    "    parser.add_argument('--weighted_sampling', type=str2bool, default = False) # 221124 추가\n",
    "    parser.add_argument('--weighted_cross_entropy', type=str2bool, default = False) # 221124 추가\n",
    "    parser.add_argument('--focal_loss', type=str2bool, default = False) # 221124 추가\n",
    "    parser.add_argument('--gamma', type=int) # 221124 추가\n",
    "    \n",
    "    # PTM model\n",
    "    parser.add_argument('--ptm_path', type=str)\n",
    "    parser.add_argument('--model_path', type=str)\n",
    "    parser.add_argument('--pool', type=str, default = 'cls')\n",
    "    \n",
    "    # model input\n",
    "    parser.add_argument('--max_length', type=int)\n",
    "    \n",
    "    # distributed 관련\n",
    "    parser.add_argument('--local_rank', type=int, default = -1)\n",
    "    parser.add_argument('--distributed', type=str2bool, default = False)\n",
    "    parser.add_argument('--early_stop', type=str2bool, default = True) # XXX220919\n",
    "    parser.add_argument('--early_stop_metric', type=str, default = 'loss') # 230619 추가\n",
    "    parser.add_argument('--early_stop_metric_is_max_better', type=str2bool, default = False) # 230619 추가\n",
    "    parser.add_argument('--patience', type=int, default = 3)\n",
    "    parser.add_argument('--save_model_every_epoch', type=str2bool, default = False) # 230619 추가\n",
    "    \n",
    "    args,_  = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "def train():\n",
    "    \n",
    "\n",
    "def get_tokenizer_and_model(args):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.ptm_path)\n",
    "    config = AutoConfig.from_pretrained(args.ptm_path)\n",
    "    if 'bert' in args.ptm_path:\n",
    "        model_class = BertModel\n",
    "    elif 'roberta' in args.ptm_path:\n",
    "        model_class = RobertaModel\n",
    "    elif 'ulm' in args.ptm_path:\n",
    "        model_class = T5EncoderModel\n",
    "    model = ClassificationModel(config, args.pool, model_class, args.n_labels)\n",
    "    if args.model_path is None:\n",
    "        if 'ulm' in args.ptm_path:\n",
    "            backbone_model = T5EncoderModel.from_pretrained(args.ptm_path)\n",
    "        else:\n",
    "            backbone_model = AutoModel.from_pretrained(args.ptm_path)\n",
    "        model.init_pretrained_model(backbone_model.state_dict())\n",
    "    else:\n",
    "        model_state_dict = torch.load(args.model_path, map_location='cpu')\n",
    "        model.load_state_dict(model_state_dict)\n",
    "    return tokenizer, model \n",
    "\n",
    "def load_datasets(args, tokenizer):\n",
    "    # LOAD DATASETS\n",
    "    train_data = load_jsonl(args.train_data)\n",
    "    train_dataset = ClassificationDataset(train_data, tokenizer, args.max_length)\n",
    "    if args.distributed:\n",
    "        # OK - legacy\n",
    "        val_data = load_data(args.val_data, args.local_rank, args.distributed)\n",
    "    else:\n",
    "        val_data = load_jsonl(args.val_data)\n",
    "    val_dataset = ClassificationDataset(val_data, tokenizer, args.max_length)\n",
    "    return train_dataset, val_dataset\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6532f0d6-5363-496f-8b31-8c17da7c93f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-20 15:15:37,380][stream][INFO] >> Namespace(test_name='log', output_dir='D:/jupyter_notebook/output/classification/nli/roberta/base', train_data='D:/jupyter_notebook/data/NLI/train.jsonl', val_data='D:/jupyter_notebook/data/NLI/dev.jsonl', n_labels=3, logging_term=1000, epochs=5, eval_epoch=10, batch_size=4, lr=0.0001, warmup=100, decay=0.1, accumulation_steps=128, fp16=True, weighted_sampling=False, weighted_cross_entropy=False, focal_loss=False, gamma=None, ptm_path='klue/roberta-base', model_path=None, pool='mean', max_length=512, local_rank=-1, distributed=False, early_stop=True, early_stop_metric='acc', early_stop_metric_is_max_better=True, patience=3, save_model_every_epoch=True)\n",
      "[2023-06-20 15:15:37,380][stream][INFO] >> Namespace(test_name='log', output_dir='D:/jupyter_notebook/output/classification/nli/roberta/base', train_data='D:/jupyter_notebook/data/NLI/train.jsonl', val_data='D:/jupyter_notebook/data/NLI/dev.jsonl', n_labels=3, logging_term=1000, epochs=5, eval_epoch=10, batch_size=4, lr=0.0001, warmup=100, decay=0.1, accumulation_steps=128, fp16=True, weighted_sampling=False, weighted_cross_entropy=False, focal_loss=False, gamma=None, ptm_path='klue/roberta-base', model_path=None, pool='mean', max_length=512, local_rank=-1, distributed=False, early_stop=True, early_stop_metric='acc', early_stop_metric_is_max_better=True, patience=3, save_model_every_epoch=True)\n",
      "[2023-06-20 15:15:37,380][stream][INFO] >> Namespace(test_name='log', output_dir='D:/jupyter_notebook/output/classification/nli/roberta/base', train_data='D:/jupyter_notebook/data/NLI/train.jsonl', val_data='D:/jupyter_notebook/data/NLI/dev.jsonl', n_labels=3, logging_term=1000, epochs=5, eval_epoch=10, batch_size=4, lr=0.0001, warmup=100, decay=0.1, accumulation_steps=128, fp16=True, weighted_sampling=False, weighted_cross_entropy=False, focal_loss=False, gamma=None, ptm_path='klue/roberta-base', model_path=None, pool='mean', max_length=512, local_rank=-1, distributed=False, early_stop=True, early_stop_metric='acc', early_stop_metric_is_max_better=True, patience=3, save_model_every_epoch=True)\n",
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "957535it [00:03, 269601.21it/s]\n",
      "4570it [00:00, 267611.89it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    args  = get_args()\n",
    "    args.output_dir='D:/jupyter_notebook/output/classification/nli/roberta/base'\n",
    "    args.train_data='D:/jupyter_notebook/data/NLI/train.jsonl'\n",
    "    args.val_data='D:/jupyter_notebook/data/NLI/dev.jsonl'\n",
    "    args.logging_term=1000 \n",
    "    args.epochs=5\n",
    "    args.eval_epoch=10 \n",
    "    args.batch_size=4 \n",
    "    args.warmup=100 \n",
    "    args.ptm_path='klue/roberta-base' \n",
    "    args.max_length=512 \n",
    "    args.early_stop=True \n",
    "    args.early_stop_metric='acc' \n",
    "    args.early_stop_metric_is_max_better=True \n",
    "    args.save_model_every_epoch=True \n",
    "    args.patience=3 \n",
    "    args.lr=1e-4 \n",
    "    args.fp16=True \n",
    "    args.accumulation_steps=128 \n",
    "    args.pool='mean' \n",
    "    args.n_labels=3\n",
    "    seed_everything(42)\n",
    "    os.makedirs(args.output_dir, exist_ok = True)\n",
    "    \n",
    "    logger1, logger2 = get_log(args)\n",
    "    if args.local_rank in [-1,0]:\n",
    "        logger1.info(args)\n",
    "        logger2.info(args)\n",
    "        \n",
    "    ########################################################################################\n",
    "    # tokenizer, model load\n",
    "    ########################################################################################\n",
    "    tokenizer, model = get_tokenizer_and_model(args)\n",
    "    ########################################################################################\n",
    "    \n",
    "    ########################################################################################\n",
    "    # distributed 관련\n",
    "    ########################################################################################\n",
    "    if args.distributed:\n",
    "        assert torch.cuda.is_available()\n",
    "        assert torch.cuda.device_count()>1\n",
    "        # 이 프로세스가 어느 gpu에 할당되는지 명시\n",
    "        torch.cuda.set_device(args.local_rank)\n",
    "        # 통신을 위한 초기화\n",
    "        torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
    "        model.cuda()\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],output_device = args.local_rank)\n",
    "    else:\n",
    "        model.cuda()\n",
    "    ########################################################################################\n",
    "    \n",
    "    ########################################################################################\n",
    "    # data\n",
    "    ########################################################################################\n",
    "    train_dataset, val_dataset = load_datasets(args, tokenizer)\n",
    "    \n",
    "    # binary weight\n",
    "    weights = None\n",
    "    if args.weighted_cross_entropy:\n",
    "        labels = [i['label'] for i in train_dataset]\n",
    "        weights = torch.tensor([1/labels.count(0), 1/labels.count(1)])\n",
    "    args.weights = weights\n",
    "    # save\n",
    "    if args.local_rank in [-1,0]:\n",
    "        with open(os.path.join(args.output_dir,'args.txt'), 'w') as f:\n",
    "            json.dump(args.__dict__, f, indent=2)\n",
    "    # weighted_sampling & distributed\n",
    "    if args.weighted_sampling:\n",
    "        if args.distributed:\n",
    "            train_sampler = DistributedWeightedRandomSampler(train_dataset, replacement=True)\n",
    "        else:\n",
    "            n_class = Counter([i['label'] for i in train_dataset]) \n",
    "            class_weight = {i:1/j for i,j in n_class.items()}\n",
    "            weight =  torch.DoubleTensor([class_weight[i['label']] for i in train_dataset])\n",
    "            train_sampler = WeightedRandomSampler(weight, len(train_dataset), replacement=True)\n",
    "    else:\n",
    "        if args.distributed:\n",
    "            train_sampler = DistributedSampler(train_dataset) \n",
    "        else:\n",
    "            train_sampler = RandomSampler(train_dataset)\n",
    "   \n",
    "    train_dataloader = DataLoader(train_dataset,batch_size = args.batch_size, sampler = train_sampler, collate_fn = train_dataset.collate_fn)\n",
    "    val_sampler = SequentialSampler(val_dataset)\n",
    "    val_dataloader = DataLoader(val_dataset,batch_size = args.batch_size, sampler = val_sampler, collate_fn = val_dataset.collate_fn)\n",
    "    ########################################################################################\n",
    "    \n",
    "    ########################################################################################\n",
    "    # train\n",
    "    ########################################################################################\n",
    "    #train()\n",
    "    ########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e31efc0-ee95-4a82-875b-dffc47c7f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer_grouped_parameters = make_optimizer_group(model, args.decay)\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=args.lr, weight_decay=args.decay)\n",
    "# scheduler\n",
    "t_total = len(train_dataloader)*args.epochs//args.accumulation_steps\n",
    "n_warmup = int(t_total*args.warmup) if args.warmup<1 else int(args.warmup)\n",
    "scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=n_warmup)\n",
    "if args.local_rank in [-1,0]:\n",
    "    early_stop = EarlyStopping(args.patience, args.output_dir, max = args.early_stop_metric_is_max_better, min_difference=1e-5)\n",
    "if args.fp16:\n",
    "    scaler = GradScaler()\n",
    "flag_tensor = torch.zeros(1).cuda()\n",
    "########################################################################################\n",
    "# train\n",
    "########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1c1e0ba-3bf2-4df2-a078-b1c78d74f816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 100%|██████████████████████████████████████████████████████████████████| 239384/239384 [01:57<00:00, 2042.38it/s]\n",
      "step:   5%|███▍                                                               | 12253/239384 [00:05<01:50, 2059.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39052/2148726945.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0miter_bar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_rank\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miter_bar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mstep\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\jupyter_notebook\\Classification\\utils\\data_utils.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'longest'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2530\u001b[1;33m             \u001b[0mencodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2531\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2532\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2614\u001b[0m                 )\n\u001b[0;32m   2615\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2616\u001b[1;33m             return self.batch_encode_plus(\n\u001b[0m\u001b[0;32m   2617\u001b[0m                 \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2618\u001b[0m                 \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2805\u001b[0m         )\n\u001b[0;32m   2806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2807\u001b[1;33m         return self._batch_encode_plus(\n\u001b[0m\u001b[0;32m   2808\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2809\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    426\u001b[0m         )\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         encodings = self._tokenizer.encode_batch(\n\u001b[0m\u001b[0;32m    429\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "train_plot = []\n",
    "val_plot = []\n",
    "for epoch in range(1, args.epochs+1):\n",
    "    if args.distributed:\n",
    "        train_sampler.set_epoch(epoch)\n",
    "    model.train()\n",
    "    Loss = 0.\n",
    "    step = 0\n",
    "    iter_bar = tqdm(train_dataloader, desc='step', disable=args.local_rank not in [-1,0])\n",
    "    #train\n",
    "    for data in iter_bar:\n",
    "        step+=1\n",
    "        if args.fp16:\n",
    "            with autocast():\n",
    "                if step%args.accumulation_steps==0 or (\n",
    "                len(train_dataloader) <= args.accumulation_steps\n",
    "                and (step) == len(train_dataloader)\n",
    "        ):\n",
    "                    scheduler.step()\n",
    "                    train_plot.append(scheduler.get_last_lr()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5dd569c-195c-467e-868d-b71057b504a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ea4ecd-4beb-4c10-a23b-cdf5951c78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2006ebb-17be-4696-8336-f3dfc91c97d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cbab797640>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
